<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Thomas Hegghammer" />


<title>Using Google Document AI with R</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Using Google Document AI with R</h1>
<h4 class="author">Thomas Hegghammer</h4>



<p><strong>Last updated 14 April 2021</strong><br />
<strong>Command line users: See <a href="https://dair.info/articles/gcs_cli.html">here</a> for GCS setup
using gcloud CLI.</strong><br />
<br />
</p>
<div id="about-document-ai" class="section level2">
<h2>About Document AI</h2>
<p><a href="https://cloud.google.com/document-ai">Google Document AI</a>
(DAI) is a server-based OCR engine that extracts text from pdf files.
Released in November 2020, it is much more powerful than static
libraries such as <a href="https://github.com/tesseract-ocr/tesseract"><code>tesseract</code></a>.
Short of corpus-specific, self-trained processors, DAI offers some of
the best OCR capabilities currently available to the general public. At
the time of writing, DAI is more expensive than Amazon’s <a href="https://aws.amazon.com/textract/">Textract</a>, but promises to
support many more languages.</p>
<p>DAI is accessed through an API, but this API currently has no
official R <a href="https://cloud.google.com/document-ai/docs/libraries">client
library</a>. This is where the <code>daiR</code> package comes in; it
provides a light wrapper for DAI’s <a href="https://cloud.google.com/document-ai/docs/reference/rest">REST
API</a>, making it possible to submit documents to DAI from within R. In
addition, <code>daiR</code> comes with pre- and postprocessing tools
intended to make the whole text extraction process easier.</p>
<p>Google Document AI is closely connected with <a href="https://cloud.google.com/storage">Google Storage</a>, as the
latter serves as a drop-off and pick-up point for files you want
processed in DAI. An R workflow for DAI processing consists of three
core steps:</p>
<ol style="list-style-type: decimal">
<li>Upload your files to a Google Storage bucket. This can be done
manually in the <a href="https://console.cloud.google.com/storage/">Google Cloud
Console</a> or programmatically with the package <a href="https://code.markedmondson.me/googleCloudStorageR/index.html"><code>googleCloudStorager</code></a>.</li>
<li>Using <code>daiR</code>, tell DAI to process the files in your
bucket. DAI will return its output to your Storage bucket in the form of
json files.</li>
<li>Download the json files from your Storage bucket to your hard drive.
Again you can use either the Cloud Console or
<code>googleCloudStorager</code>.</li>
</ol>
</div>
<div id="setup" class="section level2">
<h2>Setup</h2>
<p>A <a href="https://dair.info/articles/setting_up_google_storage.html">previous
vignette</a> covered the setting up of a Google Cloud service account
and interacting with Google Storage. Here we pick up from where that
vignette left off, and assume that the following things are in
place:</p>
<ol style="list-style-type: decimal">
<li>A Google Cloud Services (GCS) <strong>project</strong> linked to
your billing account and with the Document AI API enabled.</li>
<li>A <strong>service account</strong> with the role “Owner”.</li>
<li>A <strong>json file</strong> with the service account key, the path
to which is stored in an environment variable called
<code>GCS_AUTH_FILE</code>.</li>
<li>The name of your default bucket stored in an environment variable
called <code>GCS_DEFAULT_BUCKET</code>.</li>
</ol>
<p>To use Document AI, we need to complete a few more steps.</p>
<div id="step-1-activate-document-ai" class="section level3">
<h3>Step 1: Activate Document AI</h3>
<p>First, we must activate the API. Go to the <a href="https://console.cloud.google.com/">Google Cloud Console</a> and
open the navigation menu on the left hand side. Click on “APIs and
services”. Then click on “Enable APIs and Services”, type “document ai”
in the search field, click on “cloud document ai API”, and then
“Enable”.</p>
</div>
<div id="step-2-create-a-processor" class="section level3">
<h3>Step 2: Create a processor</h3>
<p>Open the navigation menu on the left again. Scroll down, almost to
the bottom, till you see “Document AI” (under the group heading
“Artificial intelligence”). Click on “Document AI”.</p>
<p>Now click the blue button labelled “Create processor”. On the next
page, choose the “Document OCR” processor type. A pane should open on
your right where you can choose a name for the processor. Call it what
you like; the name is mainly for your own reference. Select a location
(where you want your files to be processed), then click create.</p>
<p>You should now see a page listing the processor’s Name, ID, Status
and other attributes. The main thing you want here is the
<strong>ID</strong>. Select it and copy it to the clipboard.</p>
</div>
<div id="step-3-store-the-processor-id-as-an-environment-variable" class="section level3">
<h3>Step 3: Store the processor id as an environment variable</h3>
<p>Open your <code>.Renviron</code> file by calling
<code>usethis::edit_r_environ()</code>. Add
<code>DAI_PROCESSOR_ID=&quot;&lt;your processor id&gt;&quot;</code> on a separate
line. Save <code>.Renviron</code> and restart RStudio.</p>
<p>That’s it. If these things are in place, you can start processing
right after loading the package.</p>
<p><strong>A note on access tokens</strong>: Unlike some other GCS
wrappers, daiR does not authenticate on startup and store access tokens
in the environment. Instead it generates tokens on a per-call basis. If
you prefer to generate one token per session, you can use
<code>dai_token()</code> to store your token in an object and pass that
object directly into the API call functions using the latter’s
<code>token =</code> parameter. This also means you can use auth
functions from pretty much any other GCS wrapper to generate your
token.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">library</span>(daiR)</span></code></pre></div>
<p>Now let’s try this thing out.</p>
</div>
</div>
<div id="synchronous-processing" class="section level2">
<h2>Synchronous processing</h2>
<p>The quickest and easiest way to OCR with DAI is through synchronous
processing. You simply pass an image file or a pdf (of up to 5 pages) to
the processor and get the result into your R environment within
seconds.</p>
<p>We can try with a sample pdf from the CIA’s Freedom of Information
Act Electronic Reading Room:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="fu">setwd</span>(<span class="fu">tempdir</span>())</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="fu">download.file</span>(<span class="st">&quot;https://www.cia.gov/readingroom/docs/AGH%2C%20LASLO_0011.pdf&quot;</span>, </span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>              <span class="at">destfile =</span> <span class="st">&quot;CIA.pdf&quot;</span>, </span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>              <span class="at">mode =</span> <span class="st">&quot;wb&quot;</span>)</span></code></pre></div>
<p>We send it to Document AI with <code>dai_sync()</code> and store the
HTTP response in an object, for example <code>response</code>.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>response1 <span class="ot">&lt;-</span> <span class="fu">dai_sync</span>(<span class="st">&quot;CIA.pdf&quot;</span>)</span></code></pre></div>
<p>Then we extract the text with
<code>text_from_dai_response()</code>:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a>text <span class="ot">&lt;-</span> <span class="fu">text_from_dai_response</span>(response1)</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="fu">cat</span>(text)</span></code></pre></div>
<p>Synchronous processing is very convenient, but has two limitations.
One is that OCR accuracy may be slightly reduced compared with
asynchronous processing, because <code>dai_sync()</code> converts the
source file to a lightweight, grayscale image before passing it to DAI.
The other is scaling; If you have a large pdf or many files, it is
usually easier to process them asynchronously.</p>
</div>
<div id="asynchronous-processing" class="section level2">
<h2>Asynchronous processing</h2>
<p>In asynchronous (offline) processing, you don’t send DAI the actual
document, but rather its location on Google Storage so that DAI can
process it “in its own time”. While slower than synchronous OCR, it
allows for batch processing. The <code>daiR</code> function
<code>dai_async()</code> is vectorized, so you can send multiple files
with a single call. For this vignette, however, we’ll just use a single
document; the same as in the previous example.</p>
<p>The first step is to upload the source file(s) to a Google Storage
bucket where DAI can find it.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="fu">library</span>(googleCloudStorageR)</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a><span class="fu">gcs_upload</span>(<span class="st">&quot;CIA.pdf&quot;</span>)</span></code></pre></div>
<p>Let’s check that our file made it safely:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="fu">gcs_list_objects</span>()</span></code></pre></div>
<p>We’re now ready to send it off to Document AI with
<code>daiR</code>’s workhorse function, <code>dai_async()</code>, as
follows:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>response2 <span class="ot">&lt;-</span> <span class="fu">dai_async</span>(<span class="st">&quot;CIA.pdf&quot;</span>)</span></code></pre></div>
<p>A few words about this function. Its core parameter,
<code>files</code>, tells DAI what to process. You can submit either
.pdf, .gif, or .tiff files, and your <code>files</code> vector can
contain a mixture of these three file formats.</p>
<p>You can also specify a <code>dest_folder</code>: the name of the
bucket folder where you want the output. It defaults to the root of the
bucket, but you can specify another subfolder. If the folder does not
exist already, it will be created.</p>
<p>The function also takes a location parameter (<code>loc</code>),
which defaults to “eu” but can be set to “us”. It has nothing to do with
where you are based, but with which of Google’s servers will process
your files. The parameter <code>skip_rev</code> can be ignored by most;
it is for passing selected documents to human review in business
workflows. The remaining parameters default to things that are defined
by your environment variables (provided you followed the recommendations
above).</p>
<p>Back to our processing. If your call returned “status: 200”, it was
accepted by the API. This does not necessarily mean that the processing
was successful, because the API has no way of knowing right away if the
filepaths you provided exist in your bucket. If there were errors in
your filepaths, your HTTP request would get a 200, but your files would
not actually process. They would turn up as empty files in the folder
you provided. So if you see json files of around 70 bytes each in the
destination folder, you know there was something wrong with your
filenames.</p>
<p>You can check the status of a job with <code>dai_status()</code>.
Just pass the response object from your <code>dai_async()</code> into
the parentheses, and it will tell you whether the job is finished. It
won’t tell you how much time remains, but in my experience, processing
takes about 5-20 seconds per page.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="fu">dai_status</span>(response2)</span></code></pre></div>
<p>When <code>dai_status()</code> says “SUCCEEDED”, the json output
files are waiting for you in the bucket.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="fu">gcs_list_objects</span>()</span></code></pre></div>
<p>Output file names look cryptic, but there’s a logic to them, namely:
<code>&quot;&lt;job_number&gt;/&lt;document_number&gt;/&lt;filename&gt;-&lt;shard_number&gt;.json&quot;</code>
Our file will thus take the form
<code>&quot;&lt;job_number&gt;/0/CIA-0.json&quot;</code>, with
<code>&lt;job_number&gt;</code> changing from one processing call to the
next. Let us store the name in a vector for simplicity:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="do">## NOT RUN</span></span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>our_file <span class="ot">&lt;-</span> <span class="st">&quot;&lt;job_number&gt;/0/CIA-0.json&quot;</span></span></code></pre></div>
<p>Now let’s download it and save it under a simpler name:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="fu">gcs_get_object</span>(our_file, <span class="at">saveToDisk =</span> <span class="st">&quot;CIA.json&quot;</span>, <span class="at">overwrite =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p>Finally we extract the text using
<code>text_from_dai_file</code>:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a>text <span class="ot">&lt;-</span> <span class="fu">text_from_dai_file</span>(<span class="st">&quot;CIA.json&quot;</span>)</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a><span class="fu">cat</span>(text)</span></code></pre></div>
</div>
<div id="large-batches" class="section level1">
<h1>Large batches</h1>
<p>Although <code>dai_async()</code> takes batches of files, it is
constrained by Google’s <a href="https://cloud.google.com/document-ai/quotas">rate limits</a>.
Currently, a <code>dai_async()</code> call can contain maximum 50 files
(a multi-page pdf counts as one file), and you can not have more than 5
batch requests and 10 000 pages undergoing processing at any one
time.</p>
<p>Therefore, if you’re looking to process a large batch, you need to
spread the <code>dai_async()</code> calls out over time. The simplest
solution is to make a function that sends files off individually with a
small wait in between. Say we have a vector called
<code>big_batch</code> containing thousands of filenames. First we would
make a function like this:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a>process_slowly <span class="ot">&lt;-</span> <span class="cf">function</span>(file) {</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a>  <span class="fu">dai_async</span>(file)</span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a>  <span class="fu">Sys.sleep</span>(<span class="dv">15</span>)</span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a>}</span></code></pre></div>
<p>Then we would iterate it over our file vector:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="do">## NOT RUN</span></span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a><span class="fu">map</span>(big_batch, process_slowly)</span></code></pre></div>
<p>This will hold up your console for a while, so it may be worth doing
in the background as an RStudio <a href="https://posit.co/blog/rstudio-1-2-jobs/">job</a>.</p>
<p>Finding the optimal wait time for the <code>Sys-sleep()</code> may
require some trial and error. As a rule of thumb, it should approximate
the time it takes for DAI to process <em>one</em> of your files. This,
in turn, depends on the size of the files, for a 100-page pdf will take
a lot longer to process than a single-page one. In my experience, a
10-second interval works fine for a batch of single-page pdfs.
Multi-page pdfs require proportionally more time. If your files vary in
size, calibrate the wait time to the largest file, or you may get 429s
(HTTP code for “rate limit exceeded”) half way through the
iteration.</p>
<p>Although this procedure is relatively slow, it need not add much to
the overall processing time. DAI starts processing the first files it
receives right away, so when your loop ends, DAI will be mostly done
with the OCR as well.</p>
</div>
<div class="footnotes footnotes-end-of-document">
<hr />
<ol>
<li id="fn1"><p>Note that if you do not have a
<code>GCS_DEFAULT_BUCKET</code> variable in your .Renviron file, you
will need to either set a default bucket for the current session with
<code>gcs_global_bucket(&quot;&lt;a bucket name&gt;&quot;)</code> or supply a
<code>bucket = &quot;&lt;a bucket name&gt;&quot;</code> parameter explicitly
inside <code>gcs_upload()</code>.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
</ol>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
